## LLM generate

本文来看vllm的Offline Batched Inference流程。







### LLM.generate













### 为什么需要SequenceGroup







